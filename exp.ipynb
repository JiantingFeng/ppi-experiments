{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from tqdm import trange\n",
    "from scipy.stats import norm\n",
    "from loguru import logger\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config(object):\n",
    "    def __init__(self):\n",
    "        self.seed = 2024\n",
    "        self.n = 1000        # Number of labeled samples\n",
    "        self.p = 10          # Number of features\n",
    "        self.alpha = 0.05    # Significance level\n",
    "        self.n_iter = 100\n",
    "        self.savedir = 'results'\n",
    "        self.verbose = True\n",
    "\n",
    "        if not os.path.exists(self.savedir):\n",
    "            os.makedirs(self.savedir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data(n, m, p):\n",
    "    X_labeled_ols = np.random.randn(n, p)\n",
    "    X_labeled_rest = np.random.randn(n, p)\n",
    "    X_unlabeled = np.random.randn(m, p)\n",
    "    beta = np.random.randn(p)\n",
    "    assert p >= 3, \"p must be greater than or equal to 3\"\n",
    "    # Make first feature irrelevant\n",
    "    beta[0] = 0\n",
    "    # The second and third features are correlated with target\n",
    "    beta[1] = 0.05\n",
    "    beta[2] = 0.1\n",
    "\n",
    "    # Fix variance of noise as 1\n",
    "    y_ols = X_labeled_ols @ beta + np.random.randn(n)\n",
    "    y_rest = X_labeled_rest @ beta + np.random.randn(n)\n",
    "\n",
    "    return X_labeled_ols, X_labeled_rest, X_unlabeled, y_ols, y_rest, beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_orthogonal_design(n, m, p):\n",
    "    # Generate random design matrices\n",
    "    X_labeled_ols = np.random.randn(n, p)\n",
    "    X_labeled_rest = np.random.randn(n, p)\n",
    "    X_unlabeled = np.random.randn(m, p)\n",
    "    \n",
    "    # Generate orthogonal design matrices\n",
    "    X_labeled_ols_orth = np.linalg.qr(X_labeled_ols)[0]\n",
    "    X_labeled_rest_orth = np.linalg.qr(X_labeled_rest)[0]\n",
    "    X_unlabeled_orth = np.linalg.qr(X_unlabeled)[0]\n",
    "    # Generate random coefficients\n",
    "    beta = np.random.randn(p)\n",
    "    assert p >= 3, \"p must be greater than or equal to 3\"\n",
    "    # Make first feature irrelevant\n",
    "    beta[0] = 0\n",
    "    # The second and third features are correlated with target\n",
    "    beta[1] = 0.05\n",
    "    beta[2] = 0.1\n",
    "\n",
    "    # Fix variance of noise as 1\n",
    "    y_ols = X_labeled_ols_orth @ beta + np.random.randn(n)\n",
    "    y_rest = X_labeled_rest_orth @ beta + np.random.randn(n)\n",
    "\n",
    "    return X_labeled_ols_orth, X_labeled_rest_orth, X_unlabeled_orth, y_ols, y_rest, beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_ols(X, y):\n",
    "    beta_ols = np.linalg.inv(X.T @ X) @ X.T @ y\n",
    "    return beta_ols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hypothesis_testing(X, y, beta_ols, alpha):\n",
    "    # Since we fixed the variance as known\n",
    "    se = np.sqrt(np.diag(np.linalg.inv(X.T @ X)))\n",
    "    z_stat = beta_ols / se\n",
    "    p_values = 2 * (1 - norm.cdf(np.abs(z_stat)))\n",
    "    return p_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_simulation(config):\n",
    "    np.random.seed(config.seed)\n",
    "    n = config.n\n",
    "    p = config.p\n",
    "    alpha = config.alpha\n",
    "    m_var = [100, 500, 1000, 1500, 2000, 2500, 3000]  # varying number of unlabeled samples\n",
    "    \n",
    "    results = pd.DataFrame()\n",
    "    for m in m_var:\n",
    "        print(f\"Running simulation for m = {m}\")\n",
    "        type_I_error_feat_0 = np.zeros(config.n_iter)\n",
    "        power_feat_1 = np.zeros(config.n_iter)\n",
    "        power_feat_2 = np.zeros(config.n_iter)\n",
    "        for i in trange(config.n_iter):    \n",
    "            X_labeled_ols, X_labeled_rest, X_unlabeled, y_ols, y_rest = generate_data(n, m, p)\n",
    "            # X_labeled_ols, y_ols for fitting OLS model\n",
    "            # X_labeled_rest, y_rest combined with X_unlabeled for hypothesis testing\n",
    "\n",
    "            # Fit OLS model        \n",
    "            beta_ols = fit_ols(X_labeled_ols, y_ols)\n",
    "\n",
    "            # Predict on unlabeled data\n",
    "            y_unlabeled_pred = X_unlabeled @ beta_ols\n",
    "\n",
    "            # Combine labeled and unlabeled data\n",
    "            X = np.vstack([X_labeled_rest, X_unlabeled])\n",
    "            y = np.hstack([y_rest, y_unlabeled_pred])\n",
    "\n",
    "            # Fit new model on combined data and perform hypothesis testing\n",
    "            beta_ols_combined = fit_ols(X, y)\n",
    "            p_values = hypothesis_testing(X, y, beta_ols_combined, alpha)\n",
    "\n",
    "            # Check if null hypothesis is rejected for first 3 feature\n",
    "            # First feature is irrelevant, second and third are correlated with target\n",
    "            type_I_error_feat_0[i] = p_values[0] < alpha\n",
    "            power_feat_1[i] = p_values[1] < alpha\n",
    "            power_feat_2[i] = p_values[2] < alpha\n",
    "\n",
    "        # Save average type I error and power\n",
    "        type_I_error_feat_0 = np.mean(type_I_error_feat_0)\n",
    "        power_feat_1 = np.mean(power_feat_1)\n",
    "        power_feat_2 = np.mean(power_feat_2)\n",
    "        logger.info(f\"m = {m}, Type I error (feature 0) = {type_I_error_feat_0}, Power (feature 1) = {power_feat_1}, Power (feature 2) = {power_feat_2}\")\n",
    "        results[m] = {\n",
    "            'type_I_error_feat_0': type_I_error_feat_0,\n",
    "            'power_feat_1': power_feat_1,\n",
    "            'power_feat_2': power_feat_2\n",
    "        }\n",
    "\n",
    "    results.to_csv(os.path.join(config.savedir, 'results.csv'))\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_results(result, save_path):\n",
    "    \"\"\"\n",
    "    Plot type I error and power for different features.\n",
    "    \n",
    "    Args:\n",
    "        result (pd.DataFrame): DataFrame containing the results.\n",
    "        save_path (str): Path to save the plot.\n",
    "    \"\"\"\n",
    "    type_I_error_feat_0 = result.loc['type_I_error_feat_0']\n",
    "    power_feat_1 = result.loc['power_feat_1']\n",
    "    power_feat_2 = result.loc['power_feat_2']\n",
    "    \n",
    "    # Plot results\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.set_style('whitegrid')\n",
    "    sns.color_palette(\"hls\", 8)\n",
    "    plt.plot(result.columns, type_I_error_feat_0, marker='o')\n",
    "    plt.plot(result.columns, power_feat_1, marker='o')\n",
    "    plt.plot(result.columns, power_feat_2, marker='o')\n",
    "    plt.axhline(0.05, color='r', linestyle='--')\n",
    "    plt.xlabel('Number of unlabeled samples, fixed n=1000')\n",
    "    plt.ylabel('Probability')\n",
    "    plt.title('Type I error and power')\n",
    "    plt.legend(['Type I error (Feature 0)', 'Power (Feature 1)', 'Power (Feature 2)'])\n",
    "    \n",
    "    # Save the plot\n",
    "    plt.savefig(save_path, format='pdf', bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "save_path = os.path.join(Config().savedir, 'results.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running simulation for m = 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:00<00:00, 1380.96it/s]\n",
      "\u001b[32m2024-06-20 17:13:46.020\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mrun_simulation\u001b[0m:\u001b[36m45\u001b[0m - \u001b[1mm = 100, Type I error (feature 0) = 0.05, Power (feature 1) = 0.39, Power (feature 2) = 0.94\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running simulation for m = 500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:00<00:00, 1832.97it/s]\n",
      "\u001b[32m2024-06-20 17:13:46.076\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mrun_simulation\u001b[0m:\u001b[36m45\u001b[0m - \u001b[1mm = 500, Type I error (feature 0) = 0.04, Power (feature 1) = 0.58, Power (feature 2) = 1.0\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running simulation for m = 1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:00<00:00, 1587.51it/s]\n",
      "\u001b[32m2024-06-20 17:13:46.141\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mrun_simulation\u001b[0m:\u001b[36m45\u001b[0m - \u001b[1mm = 1000, Type I error (feature 0) = 0.02, Power (feature 1) = 0.63, Power (feature 2) = 0.98\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running simulation for m = 1500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:00<00:00, 1391.54it/s]\n",
      "\u001b[32m2024-06-20 17:13:46.214\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mrun_simulation\u001b[0m:\u001b[36m45\u001b[0m - \u001b[1mm = 1500, Type I error (feature 0) = 0.12, Power (feature 1) = 0.67, Power (feature 2) = 1.0\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running simulation for m = 2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:00<00:00, 1261.70it/s]\n",
      "\u001b[32m2024-06-20 17:13:46.294\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mrun_simulation\u001b[0m:\u001b[36m45\u001b[0m - \u001b[1mm = 2000, Type I error (feature 0) = 0.07, Power (feature 1) = 0.73, Power (feature 2) = 0.99\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running simulation for m = 2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:00<00:00, 1140.04it/s]\n",
      "\u001b[32m2024-06-20 17:13:46.384\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mrun_simulation\u001b[0m:\u001b[36m45\u001b[0m - \u001b[1mm = 2500, Type I error (feature 0) = 0.18, Power (feature 1) = 0.77, Power (feature 2) = 1.0\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running simulation for m = 3000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:00<00:00, 1044.98it/s]\n",
      "\u001b[32m2024-06-20 17:13:46.481\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mrun_simulation\u001b[0m:\u001b[36m45\u001b[0m - \u001b[1mm = 3000, Type I error (feature 0) = 0.17, Power (feature 1) = 0.8, Power (feature 2) = 1.0\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "result = run_simulation(Config())\n",
    "\n",
    "# Plot results\n",
    "plot_results(result, save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_simulation_orth(config):\n",
    "    np.random.seed(config.seed)\n",
    "    n = config.n\n",
    "    p = config.p\n",
    "    alpha = config.alpha\n",
    "    m_var = [100, 200, 300, 500, 800, 1000, 2000, 3000, 4000, 5000]  # varying number of unlabeled samples\n",
    "    \n",
    "    results = pd.DataFrame()\n",
    "    for m in m_var:\n",
    "        print(f\"Running simulation for m = {m}\")\n",
    "        type_I_error_feat_0 = np.zeros(config.n_iter)\n",
    "        power_feat_1 = np.zeros(config.n_iter)\n",
    "        power_feat_2 = np.zeros(config.n_iter)\n",
    "        for i in trange(config.n_iter):    \n",
    "            X_labeled, X_unlabeled, y = generate_orthogonal_design(n, m, p)\n",
    "            # X_labeled_ols, y_ols for fitting OLS model\n",
    "            # X_labeled_rest, y_rest combined with X_unlabeled for hypothesis testing\n",
    "            X_labeled_ols, X_labeled_rest = X_labeled[:n], X_labeled[n:]\n",
    "            y_ols, y_rest = y[:n], y[n:]\n",
    "\n",
    "            # Fit OLS model        \n",
    "            beta_ols = fit_ols(X_labeled_ols, y_ols)\n",
    "\n",
    "            # Predict on unlabeled data\n",
    "            y_unlabeled_pred = X_unlabeled @ beta_ols\n",
    "\n",
    "            # Combine labeled and unlabeled data\n",
    "            X = np.vstack([X_labeled_rest, X_unlabeled])\n",
    "            y = np.hstack([y_rest, y_unlabeled_pred])\n",
    "\n",
    "            # Fit new model on combined data and perform hypothesis testing\n",
    "            beta_ols_combined = fit_ols(X, y)\n",
    "            p_values = hypothesis_testing(X, y, beta_ols_combined, alpha)\n",
    "\n",
    "            # Check if null hypothesis is rejected for first 3 feature\n",
    "            # First feature is irrelevant, second and third are correlated with target\n",
    "            type_I_error_feat_0[i] = p_values[0] < alpha\n",
    "            power_feat_1[i] = p_values[1] < alpha\n",
    "            power_feat_2[i] = p_values[2] < alpha\n",
    "\n",
    "        # Save average type I error and power\n",
    "        type_I_error_feat_0 = np.mean(type_I_error_feat_0)\n",
    "        power_feat_1 = np.mean(power_feat_1)\n",
    "        power_feat_2 = np.mean(power_feat_2)\n",
    "        logger.info(f\"m = {m}, Type I error (feature 0) = {type_I_error_feat_0}, Power (feature 1) = {power_feat_1}, Power (feature 2) = {power_feat_2}\")\n",
    "        results[m] = {\n",
    "            'type_I_error_feat_0': type_I_error_feat_0,\n",
    "            'power_feat_1': power_feat_1,\n",
    "            'power_feat_2': power_feat_2\n",
    "        }\n",
    "\n",
    "    results.to_csv(os.path.join(config.savedir, 'results_orth.csv'))\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running simulation for m = 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m result_orth \u001b[38;5;241m=\u001b[39m \u001b[43mrun_simulation_orth\u001b[49m\u001b[43m(\u001b[49m\u001b[43mConfig\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m save_path_orth \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(Config()\u001b[38;5;241m.\u001b[39msavedir, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresults_orth.pdf\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      5\u001b[0m plot_results(result_orth, save_path_orth)\n",
      "Cell \u001b[0;32mIn[9], line 15\u001b[0m, in \u001b[0;36mrun_simulation_orth\u001b[0;34m(config)\u001b[0m\n\u001b[1;32m     13\u001b[0m power_feat_2 \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros(config\u001b[38;5;241m.\u001b[39mn_iter)\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m trange(config\u001b[38;5;241m.\u001b[39mn_iter):    \n\u001b[0;32m---> 15\u001b[0m     X_labeled, X_unlabeled, y \u001b[38;5;241m=\u001b[39m generate_orthogonal_design(n, m, p)\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;66;03m# X_labeled_ols, y_ols for fitting OLS model\u001b[39;00m\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;66;03m# X_labeled_rest, y_rest combined with X_unlabeled for hypothesis testing\u001b[39;00m\n\u001b[1;32m     18\u001b[0m     X_labeled_ols, X_labeled_rest \u001b[38;5;241m=\u001b[39m X_labeled[:n], X_labeled[n:]\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 3)"
     ]
    }
   ],
   "source": [
    "result_orth = run_simulation_orth(Config())\n",
    "\n",
    "save_path_orth = os.path.join(Config().savedir, 'results_orth.pdf')\n",
    "\n",
    "plot_results(result_orth, save_path_orth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.221269758799057e-16\n"
     ]
    }
   ],
   "source": [
    "# Test generate_orthogonal_design\n",
    "n = 1000\n",
    "m = 2000\n",
    "p = 10\n",
    "X_labeled, X_unlabeled, y = generate_orthogonal_design(n, m, p)\n",
    "assert X_labeled.shape == (2 * n, p)\n",
    "assert X_unlabeled.shape == (m, p)\n",
    "\n",
    "# test whether the design matrices are orthogonal\n",
    "assert np.allclose(X_labeled.T @ X_labeled, np.eye(p))\n",
    "# print the norm of the correlation matrix\n",
    "print(np.linalg.norm(X_labeled.T @ X_labeled - np.eye(p)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
