{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from temperature_scaling import ModelWithTemperature\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "import timm\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data, and split train into train and validation\n",
    "\n",
    "batch_size = 512\n",
    "\n",
    "mnist_train = datasets.MNIST('data', train=True, download=True, transform=transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,)),\n",
    "]), )\n",
    "\n",
    "mnist_train, mnist_val = torch.utils.data.random_split(mnist_train, [50000, 10000])\n",
    "\n",
    "# Split train dataset into labeled and unlabeled\n",
    "mnist_train_labeled = torch.utils.data.Subset(mnist_train, np.where(np.array(mnist_train.indices) < 10000)[0])\n",
    "mnist_train_unlabeled = torch.utils.data.Subset(mnist_train, np.where(np.array(mnist_train.indices) >= 10000)[0])\n",
    "\n",
    "train_labeled_loader = torch.utils.data.DataLoader(mnist_train_labeled, batch_size=batch_size, shuffle=True)\n",
    "train_unlabeled_loader = torch.utils.data.DataLoader(mnist_train_unlabeled, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(mnist_val, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('data', train=False, download=True, transform=transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.1307,), (0.3081,)),\n",
    "    ])),\n",
    "    batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data:  torch.Size([512, 1, 28, 28])\n",
      "Target:  torch.Size([512])\n"
     ]
    }
   ],
   "source": [
    "# Test the data loader\n",
    "\n",
    "for data, target in train_labeled_loader:\n",
    "    print(\"Data: \", data.size())\n",
    "    print(\"Target: \", target.size())\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(28*28, 100),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(100, 10),\n",
    ")\n",
    "\n",
    "model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "def train(model, optimizer, train_loader, val_loader, epochs=10):\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for batch_idx, (data, target) in enumerate(train_loader):\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = F.cross_entropy(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            pred = output.argmax(dim=1, keepdim=True)\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "            total += data.size(0)\n",
    "        print(f\"Train accuracy: {correct/total:.4f}\")\n",
    "\n",
    "        model.eval()\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for batch_idx, (data, target) in enumerate(val_loader):\n",
    "                data, target = data.cuda(), target.cuda()\n",
    "                output = model(data)\n",
    "                pred = output.argmax(dim=1, keepdim=True)\n",
    "                correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "                total += data.size(0)\n",
    "        print(f\"Validation accuracy: {correct/total:.4f}\")\n",
    "        model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.9931\n",
      "Validation accuracy: 0.9363\n",
      "Train accuracy: 0.9932\n",
      "Validation accuracy: 0.9381\n",
      "Train accuracy: 0.9937\n",
      "Validation accuracy: 0.9363\n",
      "Train accuracy: 0.9940\n",
      "Validation accuracy: 0.9376\n",
      "Train accuracy: 0.9937\n",
      "Validation accuracy: 0.9368\n",
      "Train accuracy: 0.9946\n",
      "Validation accuracy: 0.9371\n",
      "Train accuracy: 0.9944\n",
      "Validation accuracy: 0.9364\n",
      "Train accuracy: 0.9948\n",
      "Validation accuracy: 0.9371\n",
      "Train accuracy: 0.9945\n",
      "Validation accuracy: 0.9376\n",
      "Train accuracy: 0.9952\n",
      "Validation accuracy: 0.9372\n"
     ]
    }
   ],
   "source": [
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "train(model, optimizer, train_labeled_loader, val_loader, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use model to generate pseudo-labels for unlabeled data\n",
    "\n",
    "def generate_pseudo_labels(model, unlabeled_loader):\n",
    "    model.eval()\n",
    "    pseudo_labels = []\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (data, target) in enumerate(unlabeled_loader):\n",
    "            data = data.cuda()\n",
    "            output = model(data)\n",
    "            pseudo_labels.append(output.argmax(dim=1))\n",
    "    return torch.cat(pseudo_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = generate_pseudo_labels(model, train_unlabeled_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine labeled and pseudo-labeled data, note that train_unlabeled_loader is Subset of mnist_train_unlabeled, so we need to access the dataset attribute of the loader to get the original dataset\n",
    "\n",
    "mnist_train_unlabeled = train_unlabeled_loader.dataset\n",
    "mnist_train_unlabeled.targets = labels\n",
    "\n",
    "mnist_train_combined = torch.utils.data.ConcatDataset([mnist_train_labeled.dataset, mnist_train_unlabeled])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the logistic regression model on the combined dataset, return the regression coefficients\n",
    "\n",
    "def train_logistic_regression(model, optimizer, train_loader, test_loader, epochs=10):\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for batch_idx, (data, target) in enumerate(train_loader):\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = F.cross_entropy(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            pred = output.argmax(dim=1, keepdim=True)\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "            total += data.size(0)\n",
    "        print(f\"Train accuracy: {correct/total:.4f}\")\n",
    "    \n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (data, target) in enumerate(test_loader):\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "            output = model(data)\n",
    "            pred = output.argmax(dim=1, keepdim=True)\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "            total += data.size(0)\n",
    "\n",
    "    print(f\"Test accuracy: {correct/total:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.6436\n",
      "Train accuracy: 0.8721\n",
      "Train accuracy: 0.8927\n",
      "Train accuracy: 0.8997\n",
      "Train accuracy: 0.9090\n",
      "Train accuracy: 0.9125\n",
      "Train accuracy: 0.9165\n",
      "Train accuracy: 0.9208\n",
      "Train accuracy: 0.9215\n",
      "Train accuracy: 0.9235\n",
      "Test accuracy: 0.9067\n"
     ]
    }
   ],
   "source": [
    "# Train a logistic regression model on the labeled data\n",
    "\n",
    "logistic_model_labeled = nn.Sequential(\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(28*28, 10),\n",
    ")\n",
    "\n",
    "logistic_model_labeled = logistic_model_labeled.cuda()\n",
    "\n",
    "optimizer = optim.SGD(logistic_model_labeled.parameters(), lr=0.01, momentum=0.9)\n",
    "train_logistic_regression(logistic_model_labeled, optimizer, train_labeled_loader, test_loader, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.8704\n",
      "Train accuracy: 0.9135\n",
      "Train accuracy: 0.9184\n",
      "Train accuracy: 0.9217\n",
      "Train accuracy: 0.9234\n",
      "Train accuracy: 0.9251\n",
      "Train accuracy: 0.9262\n",
      "Train accuracy: 0.9270\n",
      "Train accuracy: 0.9278\n",
      "Train accuracy: 0.9283\n",
      "Test accuracy: 0.9225\n"
     ]
    }
   ],
   "source": [
    "# Train a logistic regression model on the combined dataset\n",
    "\n",
    "train_combined_loader = torch.utils.data.DataLoader(mnist_train_combined, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "logistic_model = nn.Sequential(\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(28*28, 10),\n",
    ")\n",
    "\n",
    "logistic_model = logistic_model.cuda()\n",
    "\n",
    "optimizer = optim.SGD(logistic_model.parameters(), lr=0.01, momentum=0.9)\n",
    "train_logistic_regression(logistic_model, optimizer, train_combined_loader, test_loader, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.8707\n",
      "Train accuracy: 0.9140\n",
      "Train accuracy: 0.9181\n",
      "Train accuracy: 0.9213\n",
      "Train accuracy: 0.9232\n",
      "Train accuracy: 0.9252\n",
      "Train accuracy: 0.9263\n",
      "Train accuracy: 0.9268\n",
      "Train accuracy: 0.9279\n",
      "Train accuracy: 0.9284\n",
      "Test accuracy: 0.9211\n"
     ]
    }
   ],
   "source": [
    "# Train a logistic regression model on the combined dataset with temperature scaling\n",
    "\n",
    "logistic_model_ts = nn.Sequential(\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(28*28, 10),\n",
    ")\n",
    "\n",
    "logistic_model_ts = logistic_model_ts.cuda()\n",
    "\n",
    "optimizer = optim.SGD(logistic_model_ts.parameters(), lr=0.01, momentum=0.9)\n",
    "train_logistic_regression(logistic_model_ts, optimizer, train_combined_loader, test_loader, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before temperature - NLL: 0.306, ECE: 0.010\n",
      "Optimal temperature: 1.269\n",
      "After temperature - NLL: 0.316, ECE: 0.048\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([1.2695], device='cuda:0', requires_grad=True)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Temperature scaling\n",
    "\n",
    "logistic_model_ts_temperature = ModelWithTemperature(logistic_model_ts)\n",
    "logistic_model_ts_temperature.set_temperature(val_loader)\n",
    "\n",
    "logistic_model_ts_temperature.temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.9211\n"
     ]
    }
   ],
   "source": [
    "# Test the temperature scaled model\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "logistic_model_ts_temperature.eval()\n",
    "with torch.no_grad():\n",
    "    for batch_idx, (data, target) in enumerate(test_loader):\n",
    "        data, target = data.cuda(), target.cuda()\n",
    "        output = logistic_model_ts_temperature(data)\n",
    "        pred = output.argmax(dim=1, keepdim=True)\n",
    "        correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "        total += data.size(0)\n",
    "\n",
    "print(f\"Test accuracy: {correct/total:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
